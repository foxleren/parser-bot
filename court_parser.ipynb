{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Сброс ограничений на количество выводимых рядов\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Сброс ограничений на число столбцов\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dump(data, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "def pickle_load(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        return data\n",
    "\n",
    "\n",
    "def protected_get_html_soup_num(href, class_name='resultsearch_text', num=5):\n",
    "    response = None\n",
    "    \n",
    "#     print(href)\n",
    "    reload_flag = 0\n",
    "    while reload_flag < num:\n",
    "        try:\n",
    "            headers = {'user-agent': '__________'}\n",
    "            response = requests.get(href, headers=headers)\n",
    "            sleep(3)\n",
    "        except:\n",
    "            print(\"Poor connection: reloaded page \" + href)\n",
    "            \n",
    "            sleep(5)\n",
    "            reload_flag += 1\n",
    "            continue\n",
    "        \n",
    "        if response is not None and response.status_code == 200:\n",
    "            raw_html = BeautifulSoup(response.content, features=\"lxml\")\n",
    "            \n",
    "            if raw_html.find('div', class_=class_name) is None:\n",
    "                print(\"Something wrong with the loaded page \" + href)\n",
    "                \n",
    "                sleep(5)\n",
    "                reload_flag += 1\n",
    "                continue\n",
    "            \n",
    "            return raw_html\n",
    "    \n",
    "    print('Can not get ' + href)\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "court_dict = {\n",
    "    'mgs': 'Московский городской суд',\n",
    "    'babushkinskij': 'Бабушкинский районный суд',\n",
    "    'basmannyj': 'Басманный районный суд',\n",
    "    'butyrskij': 'Бутырский районный суд',\n",
    "    'gagarinskij': 'Гагаринский районный суд',\n",
    "    'golovinskij': 'Головинский районный суд',\n",
    "    'dorogomilovskij': 'Дорогомиловский районный суд',\n",
    "    'zamoskvoreckij': 'Замоскворецкий районный суд',\n",
    "    'zelenogradskij': 'Зеленоградский районный суд',\n",
    "    'zyuzinskij': 'Зюзинский районный суд',\n",
    "    'izmajlovskij': 'Измайловский районный суд',\n",
    "    'koptevskij': 'Коптевский районный суд',\n",
    "    'kuzminskij': 'Кузьминский районный суд',\n",
    "    'kuncevskij': 'Кунцевский районный суд',\n",
    "    'lefortovskij': 'Лефортовский районный суд',\n",
    "    'lyublinskij': 'Люблинский районный суд',\n",
    "    'meshchanskij': 'Мещанский районный суд',\n",
    "    'nagatinskij': 'Нагатинский районный суд',\n",
    "    'nikulinskij': 'Никулинский районный суд',\n",
    "    'ostankinskij': 'Останкинский районный суд',\n",
    "    'perovskij': 'Перовский районный суд',\n",
    "    'preobrazhenskij': 'Преображенский районный суд',\n",
    "    'presnenskij': 'Пресненский районный суд',\n",
    "    'savyolovskij': 'Савёловский районный суд',\n",
    "    'simonovskij': 'Симоновский районный суд',\n",
    "    'solncevskij': 'Солнцевский районный суд',\n",
    "    'taganskij': 'Таганский районный суд',\n",
    "    'tverskoj': 'Тверской районный суд',\n",
    "    'timiryazevskij': 'Тимирязевский районный суд',\n",
    "    'troickij': 'Троицкий районный суд',\n",
    "    'tushinskij': 'Тушинский районный суд',\n",
    "    'hamovnicheskij': 'Хамовнический районный суд',\n",
    "    'horoshevskij': 'Хорошёвский районный суд',\n",
    "    'cheryomushkinskij': 'Черёмушкинский районный суд',\n",
    "    'chertanovskij': 'Чертановский районный суд',\n",
    "    'shcherbinskij': 'Щербинский районный суд',\n",
    "}\n",
    "\n",
    "possible_names = ['скилбокс', 'скиллбокс', 'skillbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_num = pickle_load('res_num.pkl')\n",
    "res_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_data = pickle_load('res_data.pkl')\n",
    "res_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_court_data(name='скилбокс'):\n",
    "    res_data = dict()\n",
    "    res_data['Запрос'] = []\n",
    "    res_data['Суд'] = []\n",
    "    res_data['Ссылка'] = []\n",
    "    res_data['Номер дела'] = []\n",
    "    # res_data['Дата парсинга'] = []\n",
    "    \n",
    "    href_prefix = \"https://mos-gorsud.ru/search?formType=shortForm&participant=\" + name\n",
    "    \n",
    "    for court in tqdm(court_dict.keys()):\n",
    "        href = href_prefix + '&courtAlias=' + court\n",
    "        raw_html = protected_get_html_soup_num(href)\n",
    "        \n",
    "        if raw_html == -1:\n",
    "            return -1\n",
    "        \n",
    "        resultsearch_text = raw_html.find('div', class_='resultsearch_text')\n",
    "        resultsearch_text = resultsearch_text.text.strip().lower()\n",
    "        \n",
    "        if 'ничего не найдено' not in resultsearch_text:\n",
    "            resultsearch_text = resultsearch_text.split('\\n')[0].strip()\n",
    "            amount_found = int(resultsearch_text.split(':')[1].strip())\n",
    "            \n",
    "            table = raw_html.find('table', class_='custom_table').find('tbody')\n",
    "            table_rows = table.find_all('tr')\n",
    "            \n",
    "            for row in table_rows:\n",
    "                request_res = name\n",
    "                court_res = court_dict[court]\n",
    "                href_res = 'https://mos-gorsud.ru' + row.find('nobr').find('a').get('href')\n",
    "                nobr_res = row.find('nobr').text.strip()\n",
    "\n",
    "                res_data['Запрос'].append(request_res)\n",
    "                res_data['Суд'].append(court_res)\n",
    "                res_data['Ссылка'].append(href_res)\n",
    "                res_data['Номер дела'].append(nobr_res)\n",
    "            \n",
    "            if len(table_rows) != amount_found:\n",
    "                new_href = href + '&page='\n",
    "                page_num = 2\n",
    "                \n",
    "                raw_html_new = protected_get_html_soup_num(new_href + str(page_num))\n",
    "                \n",
    "                if raw_html_new == -1:\n",
    "                    return -1\n",
    "                \n",
    "                resultsearch_text = raw_html_new.find('div', class_='resultsearch_text')\n",
    "                resultsearch_text = resultsearch_text.text.strip().lower()\n",
    "                \n",
    "                while 'ничего не найдено' not in resultsearch_text:\n",
    "                    table = raw_html_new.find('table', class_='custom_table').find('tbody')\n",
    "                    table_rows = table.find_all('tr')\n",
    "\n",
    "                    for row in table_rows:\n",
    "                        request_res = name\n",
    "                        court_res = court_dict[court]\n",
    "                        href_res = 'https://mos-gorsud.ru' + row.find('nobr').find('a').get('href')\n",
    "                        nobr_res = row.find('nobr').text.strip()\n",
    "\n",
    "                        res_data['Запрос'].append(request_res)\n",
    "                        res_data['Суд'].append(court_res)\n",
    "                        res_data['Ссылка'].append(href_res)\n",
    "                        res_data['Номер дела'].append(nobr_res)\n",
    "                    \n",
    "                    page_num += 1\n",
    "                    \n",
    "                    raw_html_new = protected_get_html_soup_num(new_href + str(page_num))\n",
    "                    \n",
    "                    if raw_html_new == -1:\n",
    "                        return -1\n",
    "                    \n",
    "                    resultsearch_text = raw_html_new.find('div', class_='resultsearch_text')\n",
    "                    resultsearch_text = resultsearch_text.text.strip().lower()\n",
    "    \n",
    "    return pd.DataFrame(res_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_data1 = get_court_data()\n",
    "res_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_data2 = get_court_data('skilbox')\n",
    "# res_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_data = pd.concat([res_data, res_data2], ignore_index=True)\n",
    "# res_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump(res_data, 'res_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_data.to_excel('court_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(res_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'court_data.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global prev_df\n",
    "new_lines_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_new_rows(row):\n",
    "    if not prev_df.empty and any([val not in prev_df.values for val in row.values]):\n",
    "        return ['background-color: #9EC3EF'] * len(row)\n",
    "    else:\n",
    "        return [''] * len(row)\n",
    "def highlight_all_rows(row):\n",
    "    return ['background-color: #9EC3EF'] * len(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(file_path):\n",
    "    prev_df = pd.read_excel('court_data.xlsx')\n",
    "    diff = pd.concat([prev_df, res_data]).drop_duplicates(keep=False)\n",
    "    new_lines_counter = len(diff)\n",
    "    merged_table = pd.merge(prev_df,res_data, how='outer')\n",
    "    merged_table.fillna(value='', inplace=True)\n",
    "    merged_table.style.apply(highlight_new_rows, axis=1).to_excel(file_path, engine='openpyxl', index=False)\n",
    "else:\n",
    "    new_lines_counter = len(res_data)\n",
    "    res_data.style.apply(highlight_all_rows, axis=1).to_excel('court_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = str(new_lines_counter)\n",
    "subprocess.run([\"echo\", text])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
